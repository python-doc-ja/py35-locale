# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2001-2016, Python Software Foundation
# This file is distributed under the same license as the Python package.
# 
# Translators:
# Nozomu Kaneko <nozom.kaneko@gmail.com>, 2016
msgid ""
msgstr ""
"Project-Id-Version: Python 3.5\n"
"Report-Msgid-Bugs-To: \n"
"PO-Revision-Date: 2016-12-10 07:46+0000\n"
"Last-Translator: tomo\n"
"Language-Team: Japanese (http://www.transifex.com/python-doc/python-35/language/ja/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: ja\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../../library/urllib.robotparser.rst:2
msgid ":mod:`urllib.robotparser` ---  Parser for robots.txt"
msgstr ":mod:`urllib.robotparser` ---  robots.txt のためのパーザ"

#: ../../library/urllib.robotparser.rst:10
msgid "**Source code:** :source:`Lib/urllib/robotparser.py`"
msgstr "**ソースコード:** :source:`Lib/urllib/robotparser.py`"

#: ../../library/urllib.robotparser.rst:20
msgid ""
"This module provides a single class, :class:`RobotFileParser`, which answers"
" questions about whether or not a particular user agent can fetch a URL on "
"the Web site that published the :file:`robots.txt` file.  For more details "
"on the structure of :file:`robots.txt` files, see "
"http://www.robotstxt.org/orig.html."
msgstr "このモジュールでは単一のクラス、 :class:`RobotFileParser` を提供します。このクラスは、特定のユーザエージェントが :file:`robots.txt` ファイルを公開している Web サイトのある URL を取得可能かどうかの質問に答えます。 :file:`robots.txt` ファイルの構造に関する詳細は http://www.robotstxt.org/orig.html を参照してください。"

#: ../../library/urllib.robotparser.rst:28
msgid ""
"This class provides methods to read, parse and answer questions about the "
":file:`robots.txt` file at *url*."
msgstr "*url* の :file:`robots.txt` に対し読み込み、パーズ、応答するメソッドを提供します。"

#: ../../library/urllib.robotparser.rst:33
msgid "Sets the URL referring to a :file:`robots.txt` file."
msgstr ":file:`robots.txt` ファイルを参照するための URL を設定します。"

#: ../../library/urllib.robotparser.rst:37
msgid "Reads the :file:`robots.txt` URL and feeds it to the parser."
msgstr ":file:`robots.txt` URL を読み出し、パーザに入力します。"

#: ../../library/urllib.robotparser.rst:41
msgid "Parses the lines argument."
msgstr "引数 *lines* の内容を解釈します。"

#: ../../library/urllib.robotparser.rst:45
msgid ""
"Returns ``True`` if the *useragent* is allowed to fetch the *url* according "
"to the rules contained in the parsed :file:`robots.txt` file."
msgstr "解釈された :file:`robots.txt` ファイル中に記載された規則に従ったとき、 *useragent* が *url* を取得してもよい場合には ``True`` を返します。"

#: ../../library/urllib.robotparser.rst:51
msgid ""
"Returns the time the ``robots.txt`` file was last fetched.  This is useful "
"for long-running web spiders that need to check for new ``robots.txt`` files"
" periodically."
msgstr "``robots.txt`` ファイルを最後に取得した時刻を返します。この値は、定期的に新たな ``robots.txt`` をチェックする必要がある、長時間動作する Web スパイダープログラムを実装する際に便利です。"

#: ../../library/urllib.robotparser.rst:57
msgid ""
"Sets the time the ``robots.txt`` file was last fetched to the current time."
msgstr "``robots.txt`` ファイルを最後に取得した時刻を現在の時刻に設定します。"

#: ../../library/urllib.robotparser.rst:61
msgid ""
"The following example demonstrates basic use of the RobotFileParser class."
msgstr "以下にRobotFileParser クラスの利用例を示します。"
